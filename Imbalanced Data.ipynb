{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "# Vivian Zeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, recall_score,f1_score, precision_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.options.display.max_columns = None # display all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the Ames housing data set. Create a feature matrix using the following variables: Lot_Area, Year_Built, Gr_Liv_Area, Total_Bsmt_SF, and Full_Bath. Print the first few rows. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>Full_Bath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215000</td>\n",
       "      <td>31770</td>\n",
       "      <td>1960</td>\n",
       "      <td>1656</td>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105000</td>\n",
       "      <td>11622</td>\n",
       "      <td>1961</td>\n",
       "      <td>896</td>\n",
       "      <td>882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172000</td>\n",
       "      <td>14267</td>\n",
       "      <td>1958</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244000</td>\n",
       "      <td>11160</td>\n",
       "      <td>1968</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189900</td>\n",
       "      <td>13830</td>\n",
       "      <td>1997</td>\n",
       "      <td>1629</td>\n",
       "      <td>928</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sale_Price  Lot_Area  Year_Built  Gr_Liv_Area  Total_Bsmt_SF  Full_Bath\n",
       "0      215000     31770        1960         1656           1080          1\n",
       "1      105000     11622        1961          896            882          1\n",
       "2      172000     14267        1958         1329           1329          1\n",
       "3      244000     11160        1968         2110           2110          2\n",
       "4      189900     13830        1997         1629            928          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames = pd.read_csv('ames.csv')\n",
    "cols = ['Sale_Price', 'Lot_Area', 'Year_Built', 'Gr_Liv_Area', 'Total_Bsmt_SF', 'Full_Bath']\n",
    "df = ames[cols].copy()\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31770,  1960,  1656,  1080,     1],\n",
       "       [11622,  1961,   896,   882,     1],\n",
       "       [14267,  1958,  1329,  1329,     1],\n",
       "       [11160,  1968,  2110,  2110,     2],\n",
       "       [13830,  1997,  1629,   928,     2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df. drop('Sale_Price', axis=1).values\n",
    "X[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a vector for the response. This will be 1 if the Sale_Price is greater than $300,000, and 0 otherwise. What is the proportion of homes that have a sale price greater than 300,000? (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(df.Sale_Price.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.Sale_Price <= 300000]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.Sale_Price >300000]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the proportion of sale price greater than 300,000: 0.07849829351535836\n"
     ]
    }
   ],
   "source": [
    "print('the proportion of sale price greater than 300,000:', y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the data into training and testing sets using a 60/40 split, making sure to stratify based on the response variable. Print the dimensions of each set. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, stratify=y, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 5) (1172, 5) (1758, 1) (1172, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Standardize the features from the training set and apply the transformation to the test set. Print the first few rows of the standardized features from the training set. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10865434e-01 -2.54708797e-01 -9.38079761e-01 -4.71576501e-02\n",
      "  -1.04550661e+00]\n",
      " [ 3.03869304e+00 -2.88449892e-01  1.50742740e-01  1.26851503e+00\n",
      "   7.58223144e-01]\n",
      " [-5.60914773e-01  6.90041850e-01 -3.41437173e-01  6.21943011e-01\n",
      "   7.58223144e-01]\n",
      " [-6.64488121e-01  8.25006228e-01 -6.38754018e-01  2.88519112e-01\n",
      "   7.58223144e-01]\n",
      " [ 2.20021201e-03  9.26229512e-01  5.72611236e-01 -2.81455525e-01\n",
      "   7.58223144e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Model 1: Fit a model without any correction for the data being imbalanced. (10 pts) Fit a Logistic Regression model to the training set (using regularization is optional). Calculate and print the precision, recall, and F1 score for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression() \n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(X_test)\n",
    "probs1 = model1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5652173913043478\n",
      "Precision:  0.8253968253968254\n",
      "F1 score:  0.6709677419354838\n"
     ]
    }
   ],
   "source": [
    "print('Recall: ', recall_score(y_test, preds1))\n",
    "print('Precision: ', precision_score(y_test, preds1))\n",
    "print('F1 score: ', f1_score(y_test, preds1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model 2: Fit a model using weights to balance the classes. (10 pts)\n",
    "Fit a Logistic Regression model to the training set again, but this time use different weights for the expensive and inexpensive houses. This is done by setting the class_weight parameter to 'balanced'.\n",
    "Calculate and print the precision, recall, and F1 score for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(class_weight='balanced') \n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2.predict(X_test)\n",
    "probs2 = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9456521739130435\n",
      "Precision:  0.5\n",
      "F1 score:  0.6541353383458647\n"
     ]
    }
   ],
   "source": [
    "print('Recall: ', recall_score(y_test, preds2))\n",
    "print('Precision: ', precision_score(y_test, preds2))\n",
    "print('F1 score: ', f1_score(y_test, preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Model 3: Fit a model after oversampling the minority class. (20 pts)\n",
    "\n",
    "We first need to create a new training dataset with resampled data from the minority class. Determine how many additional observations you need from the expensive homes to make the classes balanced.\n",
    "\n",
    "Sample from the minority class with replacement so that the classes are balanced. \n",
    "\n",
    "There are many ways to do this using functions from numpy or pandas, but you may find the np.random.choice function useful to sample the indices of the expensive homes.\n",
    "\n",
    "Create a new set of features and a new response vector. Confirm that the resampling worked by printing the proportion of expensive homes in the new dataset.\n",
    "\n",
    "Print the dimensions of this new dataset.\n",
    "\n",
    "Fit a Logistic Regression model to this new training data.\n",
    "\n",
    "Calculate and print the precision, recall, and F1 score for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_over_train, y_over_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 5) (1172, 5) (3240,) (1172, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_over_train.shape, X_test.shape, y_over_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression() \n",
    "model3.fit(X_over_train, y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = model3.predict(X_test)\n",
    "probs3 = model3.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9456521739130435\n",
      "Precision:  0.5087719298245614\n",
      "F1 score:  0.6615969581749049\n"
     ]
    }
   ],
   "source": [
    "print('Recall: ', recall_score(y_test, preds3))\n",
    "print('Precision: ', precision_score(y_test, preds3))\n",
    "print('F1 score: ', f1_score(y_test, preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Model 4: Fit a model after undersampling the majority class. (20 pts)\n",
    "\n",
    "We first need to create a new training dataset after undersampling the majority class. Determine how many of the original observations you need to keep from the inexpensive homes to make the classes balanced.\n",
    "\n",
    "Sample from the majority class without replacement so that the classes are balanced.\n",
    "Create a new set of features and a new response vector. Confirm that the resampling worked by printing the proportion of expensive homes in the new dataset.\n",
    "\n",
    "Print the dimensions of this new dataset.\n",
    "\n",
    "Fit a Logistic Regression model to this new training data.\n",
    "\n",
    "Calculate and print the precision, recall, and F1 score for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_u_train, y_u_train = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_u_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 5) (1172, 5) (276,) (1172, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_u_train.shape, X_test.shape, y_u_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LogisticRegression() \n",
    "model4.fit(X_u_train, y_u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = model4.predict(X_test)\n",
    "probs4 = model4.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9565217391304348\n",
      "Precision:  0.45595854922279794\n",
      "F1 score:  0.6175438596491227\n"
     ]
    }
   ],
   "source": [
    "print('Recall: ', recall_score(y_test, preds4))\n",
    "print('Precision: ', precision_score(y_test, preds4))\n",
    "print('F1 score: ', f1_score(y_test, preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a few sentences discussing the difference in performance of the various models. (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models with about equal proportion (~50%) of each class (model 2 and 3) showed more reasonable performance in terms of F1 score. The issue for Model 1 is the unbalanced structure of the original dataset. The issue for model 2 could be due to the inadequate sample size caused by the undersampling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
